#!/bin/bash

echo "üß™ Testing German AI System"
echo "=============================="
echo ""

# Test 1: Backend Status
echo "1Ô∏è‚É£  Testing Backend..."
BACKEND_STATUS=$(curl -s http://localhost:8000/ | python3 -c "import sys, json; print(json.load(sys.stdin)['status'])" 2>/dev/null)
if [ "$BACKEND_STATUS" = "ok" ]; then
    echo "‚úÖ Backend is running"
else
    echo "‚ùå Backend is NOT running"
    exit 1
fi

# Test 2: Backend Environment
echo ""
echo "2Ô∏è‚É£  Checking Backend Environment..."
curl -s http://localhost:8000/api/v1/debug/backend-info | python3 -m json.tool
echo ""

# Test 3: GPU Ollama
echo "3Ô∏è‚É£  Testing GPU Ollama (port 11435)..."
GPU_OLLAMA=$(curl -s http://localhost:11435/api/tags 2>/dev/null)
if [ ! -z "$GPU_OLLAMA" ]; then
    echo "‚úÖ GPU Ollama is running"
    echo "   Models: $(echo $GPU_OLLAMA | python3 -c "import sys, json; models = json.load(sys.stdin)['models']; print(', '.join([m['name'] for m in models]))" 2>/dev/null)"
else
    echo "‚ùå GPU Ollama is NOT running"
fi

# Test 4: Docker Ollama
echo ""
echo "4Ô∏è‚É£  Testing Docker Ollama (port 11434)..."
DOCKER_OLLAMA=$(curl -s http://localhost:11434/api/tags 2>/dev/null)
if [ ! -z "$DOCKER_OLLAMA" ]; then
    echo "‚úÖ Docker Ollama is running"
else
    echo "‚ö†Ô∏è  Docker Ollama is NOT running (not needed for GPU mode)"
fi

# Test 5: Whisper
echo ""
echo "5Ô∏è‚É£  Testing Whisper..."
WHISPER_STATUS=$(curl -s http://localhost:9000/ 2>/dev/null)
if [ ! -z "$WHISPER_STATUS" ]; then
    echo "‚úÖ Whisper is running"
    docker compose exec whisper env | grep ASR
else
    echo "‚ùå Whisper is NOT running"
fi

# Test 6: Piper
echo ""
echo "6Ô∏è‚É£  Testing Piper..."
PIPER_STATUS=$(timeout 2 nc -z localhost 10200 2>/dev/null && echo "ok")
if [ "$PIPER_STATUS" = "ok" ]; then
    echo "‚úÖ Piper is running"
else
    echo "‚ùå Piper is NOT running"
fi

# Test 7: Voice Status
echo ""
echo "7Ô∏è‚É£  Testing Voice Features..."
curl -s http://localhost:8000/api/v1/voice/status | python3 -m json.tool
echo ""

# Summary
echo ""
echo "=============================="
echo "üìä System Summary"
echo "=============================="
echo "Backend:  Native (GPU-enabled)"
echo "Ollama:   GPU (port 11435)"
echo "Whisper:  Docker (port 9000)"
echo "Piper:    Docker (port 10200)"
echo ""
echo "Expected Performance:"
echo "  Transcribe:  0.5-1.5s (tiny model)"
echo "  Generate:    1-3s (GPU)"
echo "  Synthesize:  2-3s"
echo "  Total:       ~5-7s"
echo ""
