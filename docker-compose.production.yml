version: '3.8'

services:
  # MongoDB - Production database
  mongodb:
    image: mongo:7
    container_name: german_mongodb_prod
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD:-changeme}
      MONGO_INITDB_DATABASE: german_ai
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
      - mongodb_config:/data/configdb
    command: mongod --auth
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Redis - Caching and session storage
  redis:
    image: redis:7-alpine
    container_name: german_redis_prod
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: >
      redis-server
      --appendonly yes
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --save 60 1000
      --tcp-backlog 511
      --timeout 300
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # Ollama - AI model server (GPU accelerated)
  ollama:
    image: ollama/ollama:latest
    container_name: german_ollama_prod
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=30m
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]
      interval: 30s
      timeout: 30s
      retries: 5
      start_period: 120s

  # Whisper - Speech-to-text service
  whisper:
    image: onerahmet/openai-whisper-asr-webservice:latest-gpu
    container_name: german_whisper_prod
    restart: unless-stopped
    ports:
      - "9000:9000"
    environment:
      - ASR_MODEL=base
      - ASR_ENGINE=faster_whisper
      - ASR_LANGUAGE=de
    volumes:
      - whisper_data:/root/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Piper - Text-to-speech service
  piper:
    image: rhasspy/wyoming-piper:latest
    container_name: german_piper_prod
    restart: unless-stopped
    ports:
      - "10200:10200"
    volumes:
      - piper_data:/data
    command: --voice de_DE-eva_k-x_low
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
    healthcheck:
      test: ["CMD-SHELL", "echo 'test' | nc -z localhost 10200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: german_backend_prod
    restart: unless-stopped
    env_file:
      - ./backend/.env
    environment:
      - MONGODB_URL=mongodb://${MONGO_USER:-admin}:${MONGO_PASSWORD:-changeme}@mongodb:27017/german_ai?authSource=admin
      - REDIS_URL=redis://redis:6379
      - OLLAMA_HOST=http://ollama:11434
      - WHISPER_HOST=http://whisper:9000
      - PIPER_HOST=http://piper:10200
    ports:
      - "8000:8000"
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
      whisper:
        condition: service_healthy
      piper:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-http://localhost:8000}
    container_name: german_frontend_prod
    restart: unless-stopped
    ports:
      - "3000:3000"
    depends_on:
      backend:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Nginx - Reverse proxy and load balancer
  nginx:
    image: nginx:alpine
    container_name: german_nginx_prod
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  mongodb_data:
    driver: local
  mongodb_config:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local
  whisper_data:
    driver: local
  piper_data:
    driver: local
  nginx_logs:
    driver: local

networks:
  default:
    name: german_ai_network
    driver: bridge
