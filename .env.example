# German AI Language Learner - Environment Configuration
# Copy this file to .env and update with your actual values

# =============================================================================
# Database Configuration
# =============================================================================
# For MongoDB Atlas (recommended for production):
MONGODB_URI=mongodb+srv://username:password@cluster0.xxxxx.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0
# For local MongoDB (development only):
# MONGODB_URI=mongodb://localhost:27017

MONGODB_DB_NAME=german_ai

# =============================================================================
# Security
# =============================================================================
# Generate a secure random string (32+ characters)
# You can use: openssl rand -base64 32
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production-min-32-chars

# =============================================================================
# AI Features (Optional)
# =============================================================================
# Get your API key from: https://platform.openai.com/api-keys
# Leave empty to use database-only mode (no AI features)
OPENAI_API_KEY=

# Enable AI-powered quiz generation (only works if OPENAI_API_KEY is set)
ENABLE_AI_QUIZ_TOPUP=false

# =============================================================================
# Application Settings
# =============================================================================
# Enable speech recognition features
ALLOW_SPEECH_FEATURE=true

# Development mode settings
DEV_MODE=false
ALLOW_DEV_ROUTES=false

# =============================================================================
# Redis Configuration
# =============================================================================
# Redis connection URL (default works with docker-compose)
REDIS_URL=redis://redis:6379
REDIS_MAX_CONNECTIONS=50

# =============================================================================
# WebSocket Configuration
# =============================================================================
WS_MAX_CONNECTIONS=100
WS_HEARTBEAT_INTERVAL=30

# =============================================================================
# Ollama Configuration (Self-Hosted LLM)
# =============================================================================
# Ollama service URL (default works with docker-compose)
OLLAMA_HOST=http://ollama:11434

# Model to use (mistral:7b recommended for 24GB RAM)
# Options: mistral:7b, llama3.2:3b (lighter), qwen2.5:7b
OLLAMA_MODEL=mistral:7b

# Model parameters
OLLAMA_TIMEOUT=120
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=2048

# =============================================================================
# Feature Flags
# =============================================================================
# Enable AI conversation features (requires Ollama setup)
ENABLE_AI_CONVERSATION=false

# Enable voice features (requires Whisper + Piper setup)
ENABLE_VOICE_FEATURES=false

# Enable life simulation scenarios
ENABLE_LIFE_SIMULATION=false

# =============================================================================
# Frontend Configuration
# =============================================================================
# Frontend origin for CORS
FRONTEND_ORIGIN=http://localhost:3000

# API base URL for frontend (Next.js public env var)
NEXT_PUBLIC_API_BASE_URL=http://localhost:8000/api/v1
NEXT_PUBLIC_API_URL=http://localhost:8000
