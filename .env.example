# German AI Language Learner - Environment Configuration
# Copy this file to .env and update with your actual values

# =============================================================================
# Database Configuration
# =============================================================================
# For MongoDB Atlas (recommended for production):
MONGODB_URI=mongodb+srv://username:password@cluster0.xxxxx.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0
# For local MongoDB (development only):
# MONGODB_URI=mongodb://localhost:27017

MONGODB_DB_NAME=german_ai

# =============================================================================
# Security
# =============================================================================
# Generate a secure random string (32+ characters)
# You can use: openssl rand -base64 32
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production-min-32-chars

# =============================================================================
# AI Features (Optional)
# =============================================================================
# Get your API key from: https://platform.openai.com/api-keys
# Leave empty to use database-only mode (no AI features)
OPENAI_API_KEY=

# Enable AI-powered quiz generation (only works if OPENAI_API_KEY is set)
ENABLE_AI_QUIZ_TOPUP=false

# =============================================================================
# Application Settings
# =============================================================================
# Enable speech recognition features
ALLOW_SPEECH_FEATURE=true

# Development mode settings
DEV_MODE=false
ALLOW_DEV_ROUTES=false

# =============================================================================
# Redis Configuration
# =============================================================================
# Redis connection URL (default works with docker-compose)
REDIS_URL=redis://redis:6379
REDIS_MAX_CONNECTIONS=50

# =============================================================================
# WebSocket Configuration
# =============================================================================
WS_MAX_CONNECTIONS=100
WS_HEARTBEAT_INTERVAL=30

# =============================================================================
# Ollama Configuration (Native GPU - PERMANENT SETUP)
# =============================================================================
# IMPORTANT: Heavy AI features ALWAYS use local GPU Ollama (port 11435)
# This includes: Grammar check, Quiz generation, Scenarios, Voice chat
# 
# For Docker deployment: use http://host.docker.internal:11435
# For native backend: use http://localhost:11435
OLLAMA_HOST=http://host.docker.internal:11435

# Primary model for heavy AI tasks (Mistral 7B - best quality)
OLLAMA_MODEL=mistral:7b

# Fast model for quick responses (Llama 3.2 1B - fastest)
OLLAMA_MODEL_FAST=llama3.2:1b

# Model parameters
OLLAMA_TIMEOUT=120
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=2048
OLLAMA_KEEP_ALIVE=24h
OLLAMA_NUM_PARALLEL=2

# =============================================================================
# Whisper STT Configuration (Docker)
# =============================================================================
# Speech-to-text service for voice features
WHISPER_HOST=http://whisper:9000
WHISPER_MODEL=tiny
WHISPER_LANGUAGE=de

# =============================================================================
# Piper TTS Configuration (Docker)
# =============================================================================
# Text-to-speech service for voice features
# Professional high-quality German voice
PIPER_HOST=http://piper:10200
PIPER_VOICE=de_DE-thorsten-high
PIPER_SAMPLE_RATE=22050

# =============================================================================
# Feature Flags
# =============================================================================
# Enable AI conversation features (requires Ollama setup)
ENABLE_AI_CONVERSATION=true

# Enable voice features (requires Whisper + Piper setup)
ENABLE_VOICE_FEATURES=true

# Enable life simulation scenarios
ENABLE_LIFE_SIMULATION=true

# =============================================================================
# Frontend Configuration
# =============================================================================
# Frontend origin for CORS
FRONTEND_ORIGIN=http://localhost:3000

# API base URL for frontend (Next.js public env var)
NEXT_PUBLIC_API_BASE_URL=http://localhost:8000/api/v1
NEXT_PUBLIC_API_URL=http://localhost:8000
